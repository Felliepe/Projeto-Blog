<!DOCTYPE html>
<html lang="pt-BR">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>ciência da computação</title>
</head>

<article class="centraliza-container" id="blog">
    <h2>Explorando a evolução da ciência da computação</h2> <br> <img src="images/img6.jpg" alt="imagem de tecnologia">
    <p> <strong>Explorando a evolução da ciência da computação: dos primórdios à era digital moderna</strong> <br>

        O mundo da ciência da computação testemunhou uma jornada extraordinária desde o seu início, transformando-se de
        conceitos teóricos para uma parte integrante de nossas vidas diárias. Este artigo investiga as origens e
        progressão da ciência da computação, destacando marcos importantes que transformaram o campo no que é hoje.  <br> <br>

        <strong>O nascimento dos conceitos de computação</strong> <br>

        As sementes da ciência da computação foram plantadas há séculos com o nascimento de conceitos fundamentais. O grego antigo
        o matemático Arquimedes lançou as bases para cálculos numéricos, enquanto Charles Babbage
        imaginou dispositivos mecânicos no século 19 que poderiam realizar cálculos complexos. Sua proposta
        Motor de Diferença e Mecanismo Analítico são considerados os antecessores dos computadores modernos, sendo o último
        apresentando componentes-chave, como uma unidade lógica aritmética e uma unidade de memória. <br> <br>

        <strong>Turing e o nascimento do computador digital</strong> <br>

        O ponto de viragem na ciência da computação ocorreu durante a Segunda Guerra Mundial, quando o matemático e lógico britânico
        Alan Turing desenvolveu o conceito da máquina de Turing, um modelo teórico de computação. Isso colocou
        a base para a ideia de algoritmos e computação como uma série de etapas lógicas. O trabalho de Turing foi
        fundamental para quebrar o código Enigma alemão e é considerado um passo pioneiro em direção à computação prática.<br> <br>

        <strong>O advento dos computadores eletrônicos</strong> <br>

        A era do pós-guerra marcou a transição dos conceitos teóricos para a implementação prática. Em 1945, o
        ENIAC (Integrador Numérico Eletrônico e Computador) tornou-se o primeiro computador programável de uso geral do mundo.
        Computador digital. Esta enorme máquina, com milhares de tubos de vácuo, abriu caminho para uma nova era de
        computação eletrônica. <br> <br>

        <strong>A ascensão das linguagens de programação</strong> <br>

        À medida que os computadores evoluíram, a necessidade de formas eficientes de comunicação com eles tornou-se aparente. Isto levou ao
        desenvolvimento de linguagens de programação. Fortran (1957) foi uma das primeiras linguagens de programação de alto nível,
        projetado para simplificar cálculos científicos e de engenharia. Posteriormente, linguagens como COBOL (1959) e
        Seguiu-se LISP (1958), cada um atendendo a necessidades específicas.<br> <br>

        <strong>A revolução do computador pessoal</strong> <br>

        A década de 1970 viu o surgimento da revolução do computador pessoal (PC). Steve Jobs e Steve Wozniak
        lançou o Apple I em 1976, tornando a computação mais acessível aos indivíduos. Isto foi seguido pelo
        IBM PC em 1981, que padronizou componentes de hardware e software, levando à ampla adoção de
        computadores pessoais.<br> <br> 

        <strong>A Internet e a Era Digital</strong> <br>

        O final do século 20 trouxe o desenvolvimento mais transformador na ciência da computação – a Internet.
        Originalmente concebida como um meio de compartilhar pesquisas, a ARPANET lançou as bases para a Internet de hoje.
        Tim Berners-Lee introduziu a World Wide Web em 1989, revolucionando a forma como as informações são acessadas e
        compartilhada globalmente.<br> <br>

        <strong>O Século 21: Computação Ubíqua e IA</strong> <br>

        O século 21 testemunhou uma proliferação de dispositivos e tecnologias de computação. Smartphones,
        dispositivos vestíveis e a Internet das Coisas (IoT) tornaram a computação parte integrante do cotidiano
        vida. Além disso, os avanços em inteligência artificial (IA) e aprendizado de máquina permitiram
        computadores para executar tarefas que antes eram consideradas exclusivas da inteligência humana.<br> <br> <img src="images/banner2.png" alt="imagem">

        <strong>Conclusão:</strong> <br>

        Desde o seu humilde início como conceitos teóricos até o seu status atual como um aspecto indispensável da modernidade
        vida, o mundo da ciência da computação passou por uma evolução notável. A busca incansável pela inovação
        por visionários e cientistas nos levou dos dispositivos mecânicos para a era digital, onde os computadores estão profundamente
        integrada em todas as facetas da sociedade. Enquanto estamos à beira de novas fronteiras tecnológicas, é
        inspirador contemplar a jornada que começou com os sonhos dos pioneiros e se transformou na
        realidade digital que habitamos hoje.<br> <br>
         </p>
</article>